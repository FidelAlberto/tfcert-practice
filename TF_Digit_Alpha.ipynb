{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF - Digit Alpha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWhVY1PLprDMR7NIpQJfG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btcnhung1299/tf-practice/blob/master/TF_Digit_Alpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmtiaOnLdKyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQOPceUgdRXK",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ctqa_2dSgX",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGb0Za0dTik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "5b90d98b-cb6f-469e-d401-321d401c81ed"
      },
      "source": [
        "ds, ds_info = tfds.load(\"binary_alpha_digits\", split=\"train\",\n",
        "                        as_supervised=True, shuffle_files=True,\n",
        "                        with_info=True)\n",
        "ds_info"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='binary_alpha_digits',\n",
              "    version=1.0.0,\n",
              "    description='Binary 20x16 digits of '0' through '9' and capital 'A' through 'Z'. 39 examples of each class.',\n",
              "    homepage='https://cs.nyu.edu/~roweis/data/',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(20, 16, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=36),\n",
              "    }),\n",
              "    total_num_examples=1404,\n",
              "    splits={\n",
              "        'train': 1404,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTPuAqNQctcS",
        "colab_type": "text"
      },
      "source": [
        "**There is a huge bias in the current dataset, so shuffling needs to be done to prevent underfitting.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG5ghFN5aiVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 0.2\n",
        "\n",
        "ds_size = ds_info.splits[\"train\"].num_examples\n",
        "ds = ds.shuffle(buffer_size=ds_size)\n",
        "num_train_samples = int(ds_size * (1 - test_size))\n",
        "\n",
        "ds_train = ds.take(num_train_samples)\n",
        "ds_test = ds.skip(num_train_samples)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pQrV-ESJCvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "22c1b5e8-5073-42db-dcde-0d0a7f6396ee"
      },
      "source": [
        "for sample in ds_train.take(1):\n",
        "  X_sample, y_sample = map(lambda x : x.numpy(), sample)\n",
        "\n",
        "print(\"Pixel in range:\", X_sample.min(), '-', X_sample.max())\n",
        "print(\"Label:\", y_sample)\n",
        "plt.imshow(X_sample.squeeze(), cmap=\"gray\");"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pixel in range: 0 - 1\n",
            "Label: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANoAAAD4CAYAAACKefjmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANiklEQVR4nO3dbYxc51nG8f+FnfAhBJLUiZvYpo2KFcmpYGlWLhUBORSCbUW4RVWxhcC0kRwqLFEJCRmQmopPIBQiIFHabbHsojZJBZhaqptkCUhppL5kHTlvrYOXyJF3ce2kKU6jVgqb3HyYZ6PJeGa9njNzzzmz108azXmbc54zu9eeM2fP3I8iAjMbrp8YdQPMVgIHzSyBg2aWwEEzS+CgmSVYPeoGdCNpKJdCb7rppmGsduSOHj066iZYy8sRcXW3Garj5f1hBa2O+zoIkkbdBGs5GhGT3Wb41NEsQaWgSdoq6XlJs5L2dZn/k5IeLPO/JendVbZn1lR9B03SKuBeYBuwCdglaVPHYrcDP4iInwPuBv663+2ZNVmVI9pmYDYiXoiI14EHgB0dy+wADpbhfwY+KH+gsBWoStDWAafaxufKtK7LRMQCcA54R7eVSdojaUbSTIU2mdVSbS7vR8QUMAXDu+poNipVjmjzwIa28fVlWtdlJK0Gfgb4foVtmjVSlaA9AWyUdL2kS4GdwOGOZQ4Du8vwR4D/iHH9Z5bZEvo+dYyIBUl7gYeBVcD+iHhO0l8CMxFxGPhH4J8kzQKv0Aqj2YpTyztDJicnY2bG10SGwRd9h8p3hpiNkoNmlsBBM0vgoJklcNDMEjhoZgkcNLMEDppZAgfNLIGDZpbAQTNL4KCZJXDQzBI4aGYJHDSzBA6aWQIHzSyBg2aWoEql4g2S/lPSdyQ9J+mPuyyzRdI5ScfK41PVmmvWTFXqOi4AfxIRT0q6HDgqaToivtOx3Ncj4rYK2zFrvL6PaBFxOiKeLMM/BL7L+ZWKzYwBfUYrvcT8IvCtLrM/IOkpSV+TdOMS63irJPhLL700iGaZ1UbloEn6KeBfgE9GxKsds58E3hURvwD8A/BvvdYTEVMRMRkRk1df3bXTRLPGqto/2iW0QvbFiPjXzvkR8WpEvFaGjwCXSFpTZZtmTVTlqqNoVSL+bkT8bY9l3rnYTZOkzWV7rr1vK06Vq46/DPwe8IykY2XanwM/CxARn6FVb/8TkhaAHwM7XXvfVqIqtfcfB5asLx0R9wD39LsNs3HhO0PMEjhoZgkcNLMEDppZAgfNLEEtOyK8mM7iL6b9o+6Er47v9VJG/X41kDsiNBslB80sgYNmlsBBM0vgoJklcNDMEjhoZgkcNLMEDppZgipf/KwF371gTeAjmlkCB80swSDKzZ2U9Ewp+T3TZb4k/b2kWUlPS3pf1W2aNc2gPqPdEhEv95i3DdhYHu8H7ivPZitGxqnjDuAL0fJN4ApJ1yZs16w2BhG0AB6RdFTSni7z1wGn2sbn6FKjv70k+ADaZFYrgzh1vDki5iVdA0xLOh4Rj13sSiJiCpiCi/vip1kTVD6iRcR8eT4LHAI2dywyD2xoG19fppmtGFVr719W+kZD0mXArcCzHYsdBn6/XH38JeBcRJyusl2zpql66rgWOFTuzlgNfCkiHpL0h/BWWfAjwHZgFvgR8LGK2zRrnMYX52mSOr7XS/HtbRfNxXnMRslBM0vgoJklcNDMEjhoZgkcNLMEDppZAgfNLIGDZpbAQTNL0PgqWHZxfFvVaPiIZpbAQTNL4KCZJXDQzBI4aGYJHDSzBA6aWYK+gybphlIGfPHxqqRPdiyzRdK5tmU+Vb3JZs3T9z+sI+J5YAJA0ipaJeQOdVn06xFxW7/bMRsHgzp1/CDw3xHx4oDWZzZWBhW0ncD9PeZ9QNJTkr4m6cZeK3BJcBtnlcvNSboU+B/gxog40zHvp4E3I+I1SduBv4uIjctYZ7Pqsi1THcrN+V7HoRpqubltwJOdIQOIiFcj4rUyfAS4RNKaAWzTrFEGEbRd9DhtlPROlT+hkjaX7X1/ANs0a5RKX5Mp9fZ/A7ijbVp7OfCPAJ+QtAD8GNgZdTh/MkvmkuCJ6vBe+zPaULkkuNkoOWhmCRw0swQOmlkCB80sgatgjQFfSaw/H9HMEjhoZgkcNLMEDppZAgfNLIGDZpbAQTNL4KCZJXDQzBI4aGYJHDSzBA6aWYJlBU3SfklnJT3bNu0qSdOSTpTnK3u8dndZ5oSk3YNquFmTLPeIdgDY2jFtH/BoqdP4aBl/G0lXAXcC7wc2A3f2CqTZOFtW0CLiMeCVjsk7gINl+CDwoS4v/U1gOiJeiYgfANOcH1izsVflM9raiDhdhr8HrO2yzDrgVNv4XJlmtqIM5IufERFVS8RJ2gPsGUR7zOqmyhHtjKRrAcrz2S7LzAMb2sbXl2nniYipiJjsVRfPrMmqBO0wsHgVcTfwlS7LPAzcKunKchHk1jLNbGWJiAs+aNXWPw38H63PWbcD76B1tfEE8O/AVWXZSeDzba/9ODBbHh9b5vZiHB/DMur98uOtx0yv32mXBE80rPfaxXlqo2dJcFfBqqiOf6hsaaP4g+dbsMwSOGhmCRw0swQOmlkCB80sgYNmlsBBM0vgoJklcNDMEjhoZgl8C5bV1jjd3uYjmlkCB80sgYNmlsBBM0vgoJklcNDMEjhoZgkuGLQedff/RtJxSU9LOiTpih6vPSnpGUnHJM0MsuFmTbKcI9oBzi/jPQ28NyJ+Hvgv4M+WeP0tETHheo22kl0waNGl7n5EPBIRC2X0m7QKo5pZD4O4BevjwIM95gXwSCkf99mImOq1krqVBB/17T9NKyE36ver7ioFTdJfAAvAF3sscnNEzEu6BpiWdLwcIc9TQjhV1uufmo2Vvq86SvoD4Dbgd6PHn7OImC/PZ4FDtPpIM1tx+gqapK3AnwK/FRE/6rHMZZIuXxymVXf/2W7Lmo275Vzevx/4BnCDpDlJtwP3AJfTOh08JukzZdnrJB0pL10LPC7pKeDbwFcj4qGh7IVZzbn2fg+jfl98MaR5JPWsve87Q8wSOGhmCRw0swQOmlkCB80sgatgjQFf8as/H9HMEjhoZgkcNLMEDppZAgfNLIGDZpbAQTNL4KCZJXDQzBL4zpCa8t0ewzOK7/r5iGaWwEEzS9BvSfBPS5ov9UKOSdre47VbJT0vaVbSvkE23KxJ+i0JDnB3KfU9ERFHOmdKWgXcC2wDNgG7JG2q0lizpuqrJPgybQZmI+KFiHgdeADY0cd6zBqvyme0vaU3mf2Sruwyfx1wqm18rkzrStIeSTPudcbGUb9Buw94DzABnAbuqtqQiJiKiEn3OmPjqK+gRcSZiHgjIt4EPkf3Ut/zwIa28fVlmtmK029J8GvbRj9M91LfTwAbJV0v6VJgJ3C4n+2ZNd0F7wwpJcG3AGskzQF3AlskTdDqlukkcEdZ9jrg8xGxPSIWJO0FHgZWAfsj4rmh7IVZza2okuB13FfrrWll0QGXBDcbJQfNLIGDZpbAQTNL4KCZJXDQzBI4aGYJHDSzBA6aWQIHzSxB46tg+baqemjg7VKpfEQzS+CgmSVw0MwSOGhmCRw0swQOmlkCB80swXJqhuwHbgPORsR7y7QHgRvKIlcA/xsRE11eexL4IfAGsOBScrZSLecf1geAe4AvLE6IiN9ZHJZ0F3BuidffEhEv99tAs3FwwaBFxGOS3t1tnlq3A3wU+LXBNstsvFS9BetXgDMRcaLH/AAeKVWtPhsRU71WJGkPsKdie1Yk3/5Uf1WDtgu4f4n5N0fEvKRrgGlJx0unGecpIZyC4ZWbMxuVvq86SloN/DbwYK9lImK+PJ8FDtG9dLjZ2Ktyef/XgeMRMddtpqTLJF2+OAzcSvfS4WZjbzk9ft4PfAO4QdKcpNvLrJ10nDZKuk7SYqeEa4HHJT0FfBv4akQ8NLimmzVH40uC17H92XwxpDZcEtxslBw0swQOmlkCB80sgYNmlqDxVbDGla8kjhcf0cwSOGhmCRw0swQOmlkCB80sgYNmlsBBM0vgoJklcNDMEjhoZgnqegvWy8CLHdPWlOlvMwa3KnXdrzExrvvWa7/e1esFtfyGdTeSZsax0vG47heM7771s18+dTRL4KCZJWhS0HpWOW64cd0vGN99u+j9asxnNLMma9IRzayxHDSzBI0ImqStkp6XNCtp36jbMyiSTkp6RtIxSTOjbk8VkvZLOivp2bZpV0malnSiPF85yjb2o8d+fVrSfPm5HZO0/ULrqX3QJK0C7gW2AZuAXZI2jbZVA3VLREyMwf+bDgBbO6btAx6NiI3Ao2W8aQ5w/n4B3F1+bhMRcaTL/LepfdBo9UAzGxEvRMTrwAPAjhG3yTqU7rhe6Zi8AzhYhg8CH0pt1AD02K+L1oSgrQNOtY3PlWnjYLGjxqOlI8ZxszYiTpfh79Hq+GRc7JX0dDm1vOApcROCNs5ujoj30Tot/iNJvzrqBg1LtP6PNC7/S7oPeA8wAZwG7rrQC5oQtHlgQ9v4+jKt8VZAR41nJF0LUJ7Pjrg9AxERZyLijYh4E/gcy/i5NSFoTwAbJV0v6VJa/bIdHnGbKlshHTUeBnaX4d3AV0bYloFZ/ONRfJhl/Nzq+jWZt0TEgqS9wMPAKmB/RDw34mYNwlrgUPmaz2rgS03uqLF0WLkFWCNpDrgT+Cvgy6XzyheBj46uhf3psV9bJE3QOhU+CdxxwfX4Fiyz4WvCqaNZ4zloZgkcNLMEDppZAgfNLIGDZpbAQTNL8P+C0yXjrDpNkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzdAxI3O5vvx",
        "colab_type": "text"
      },
      "source": [
        "## Batchify dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qkKPm4lYv2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3cadfa7a-1e62-45ae-ede8-1a2b9db37602"
      },
      "source": [
        "num_classes = 10 + 26\n",
        "input_shape = next(iter(ds_train))[0].shape\n",
        "print(\"Input shape:\", input_shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (20, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUYNMSLv5zN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "88d373d3-bc26-4358-e438-34e38967719f"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "ds_train = ds_train.batch(BATCH_SIZE).shuffle(num_train_samples)\n",
        "ds_test = ds_test.batch(BATCH_SIZE).shuffle(ds_size - num_train_samples)\n",
        "\n",
        "print(ds_train, ds_test, sep=\"\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<DatasetV1Adapter shapes: ((None, 20, 16, 1), (None,)), types: (tf.uint8, tf.int64)>\n",
            "<DatasetV1Adapter shapes: ((None, 20, 16, 1), (None,)), types: (tf.uint8, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjyXnDT3TWd9",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUh9odc3d20j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af5sZbUHk4Lu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "0babe8e1-9335-4054-ba3d-7a6f5f572e38"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=input_shape))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 36)                11556     \n",
            "=================================================================\n",
            "Total params: 11,556\n",
            "Trainable params: 11,556\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81e29BP6n4v1",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgoXPIacm-94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "220b2986-32f9-4f44-e98e-ad1cac1fc5fb"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "hist = model.fit(ds_train, epochs=110, validation_data=ds_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/110\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 3.6033 - acc: 0.0623 - val_loss: 3.2386 - val_acc: 0.1068\n",
            "Epoch 2/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 3.1098 - acc: 0.1692 - val_loss: 2.8623 - val_acc: 0.2598\n",
            "Epoch 3/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 2.7732 - acc: 0.2947 - val_loss: 2.5617 - val_acc: 0.4021\n",
            "Epoch 4/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 2.5323 - acc: 0.3820 - val_loss: 2.3180 - val_acc: 0.5089\n",
            "Epoch 5/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 2.2956 - acc: 0.4702 - val_loss: 2.1017 - val_acc: 0.5552\n",
            "Epoch 6/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 2.0751 - acc: 0.5548 - val_loss: 1.9167 - val_acc: 0.5872\n",
            "Epoch 7/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.9015 - acc: 0.6020 - val_loss: 1.7997 - val_acc: 0.6228\n",
            "Epoch 8/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1.7689 - acc: 0.6367 - val_loss: 1.6957 - val_acc: 0.6441\n",
            "Epoch 9/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 1.6362 - acc: 0.6518 - val_loss: 1.5688 - val_acc: 0.6762\n",
            "Epoch 10/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.4864 - acc: 0.6830 - val_loss: 1.4608 - val_acc: 0.6904\n",
            "Epoch 11/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.4085 - acc: 0.6910 - val_loss: 1.3400 - val_acc: 0.6975\n",
            "Epoch 12/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.3095 - acc: 0.7186 - val_loss: 1.2440 - val_acc: 0.7295\n",
            "Epoch 13/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 1.2708 - acc: 0.7168 - val_loss: 1.1707 - val_acc: 0.7473\n",
            "Epoch 14/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.1870 - acc: 0.7409 - val_loss: 1.0829 - val_acc: 0.7438\n",
            "Epoch 15/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.1115 - acc: 0.7462 - val_loss: 0.9777 - val_acc: 0.8149\n",
            "Epoch 16/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 1.0763 - acc: 0.7462 - val_loss: 1.0627 - val_acc: 0.7794\n",
            "Epoch 17/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.0368 - acc: 0.7524 - val_loss: 0.9700 - val_acc: 0.7544\n",
            "Epoch 18/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.9801 - acc: 0.7694 - val_loss: 0.9529 - val_acc: 0.7794\n",
            "Epoch 19/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.9361 - acc: 0.7703 - val_loss: 0.9027 - val_acc: 0.7651\n",
            "Epoch 20/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.9156 - acc: 0.7765 - val_loss: 0.8651 - val_acc: 0.7829\n",
            "Epoch 21/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.8772 - acc: 0.7792 - val_loss: 0.7860 - val_acc: 0.8078\n",
            "Epoch 22/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.8366 - acc: 0.7943 - val_loss: 0.7931 - val_acc: 0.8007\n",
            "Epoch 23/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.8124 - acc: 0.8041 - val_loss: 0.8155 - val_acc: 0.8505\n",
            "Epoch 24/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.7672 - acc: 0.8237 - val_loss: 0.7688 - val_acc: 0.8007\n",
            "Epoch 25/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.7638 - acc: 0.8148 - val_loss: 0.6579 - val_acc: 0.8541\n",
            "Epoch 26/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.7329 - acc: 0.8192 - val_loss: 0.6941 - val_acc: 0.8256\n",
            "Epoch 27/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.7373 - acc: 0.8059 - val_loss: 0.6534 - val_acc: 0.8470\n",
            "Epoch 28/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.6964 - acc: 0.8246 - val_loss: 0.6088 - val_acc: 0.8541\n",
            "Epoch 29/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.6876 - acc: 0.8326 - val_loss: 0.6505 - val_acc: 0.8505\n",
            "Epoch 30/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.6659 - acc: 0.8255 - val_loss: 0.5907 - val_acc: 0.8577\n",
            "Epoch 31/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.6430 - acc: 0.8468 - val_loss: 0.5925 - val_acc: 0.8612\n",
            "Epoch 32/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.6278 - acc: 0.8362 - val_loss: 0.5864 - val_acc: 0.8577\n",
            "Epoch 33/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.5999 - acc: 0.8459 - val_loss: 0.5650 - val_acc: 0.8754\n",
            "Epoch 34/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.5877 - acc: 0.8504 - val_loss: 0.5682 - val_acc: 0.8719\n",
            "Epoch 35/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.5716 - acc: 0.8629 - val_loss: 0.6072 - val_acc: 0.8505\n",
            "Epoch 36/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.5635 - acc: 0.8575 - val_loss: 0.5101 - val_acc: 0.8897\n",
            "Epoch 37/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.5512 - acc: 0.8540 - val_loss: 0.4938 - val_acc: 0.8968\n",
            "Epoch 38/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.5323 - acc: 0.8593 - val_loss: 0.5152 - val_acc: 0.8790\n",
            "Epoch 39/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.5285 - acc: 0.8727 - val_loss: 0.4745 - val_acc: 0.8932\n",
            "Epoch 40/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.5033 - acc: 0.8807 - val_loss: 0.5248 - val_acc: 0.8363\n",
            "Epoch 41/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.4968 - acc: 0.8816 - val_loss: 0.4729 - val_acc: 0.8790\n",
            "Epoch 42/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4845 - acc: 0.8851 - val_loss: 0.4374 - val_acc: 0.9004\n",
            "Epoch 43/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4646 - acc: 0.8780 - val_loss: 0.4204 - val_acc: 0.8968\n",
            "Epoch 44/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.4564 - acc: 0.8958 - val_loss: 0.4340 - val_acc: 0.8932\n",
            "Epoch 45/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4573 - acc: 0.8807 - val_loss: 0.4220 - val_acc: 0.8932\n",
            "Epoch 46/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.4372 - acc: 0.8914 - val_loss: 0.4206 - val_acc: 0.9110\n",
            "Epoch 47/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.4343 - acc: 0.8931 - val_loss: 0.4320 - val_acc: 0.8932\n",
            "Epoch 48/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4162 - acc: 0.8967 - val_loss: 0.3925 - val_acc: 0.9110\n",
            "Epoch 49/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.4136 - acc: 0.8958 - val_loss: 0.4100 - val_acc: 0.8968\n",
            "Epoch 50/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4089 - acc: 0.8967 - val_loss: 0.4093 - val_acc: 0.9146\n",
            "Epoch 51/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.4061 - acc: 0.9038 - val_loss: 0.3911 - val_acc: 0.9075\n",
            "Epoch 52/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.3889 - acc: 0.9038 - val_loss: 0.3566 - val_acc: 0.9502\n",
            "Epoch 53/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.3788 - acc: 0.9154 - val_loss: 0.3590 - val_acc: 0.9181\n",
            "Epoch 54/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.3770 - acc: 0.9172 - val_loss: 0.3192 - val_acc: 0.9431\n",
            "Epoch 55/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.3742 - acc: 0.9163 - val_loss: 0.3381 - val_acc: 0.9253\n",
            "Epoch 56/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.3508 - acc: 0.9225 - val_loss: 0.3646 - val_acc: 0.9075\n",
            "Epoch 57/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.3638 - acc: 0.9163 - val_loss: 0.3569 - val_acc: 0.9110\n",
            "Epoch 58/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.3439 - acc: 0.9234 - val_loss: 0.3251 - val_acc: 0.9359\n",
            "Epoch 59/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.3390 - acc: 0.9207 - val_loss: 0.3298 - val_acc: 0.9181\n",
            "Epoch 60/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.3316 - acc: 0.9207 - val_loss: 0.2749 - val_acc: 0.9466\n",
            "Epoch 61/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.3210 - acc: 0.9288 - val_loss: 0.2907 - val_acc: 0.9502\n",
            "Epoch 62/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.3161 - acc: 0.9243 - val_loss: 0.2871 - val_acc: 0.9395\n",
            "Epoch 63/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.3088 - acc: 0.9288 - val_loss: 0.2767 - val_acc: 0.9324\n",
            "Epoch 64/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.3086 - acc: 0.9368 - val_loss: 0.3206 - val_acc: 0.9110\n",
            "Epoch 65/110\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.2973 - acc: 0.9430 - val_loss: 0.2828 - val_acc: 0.9395\n",
            "Epoch 66/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.2949 - acc: 0.9305 - val_loss: 0.2842 - val_acc: 0.9324\n",
            "Epoch 67/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.2978 - acc: 0.9323 - val_loss: 0.3091 - val_acc: 0.9288\n",
            "Epoch 68/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2853 - acc: 0.9412 - val_loss: 0.3092 - val_acc: 0.9181\n",
            "Epoch 69/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2808 - acc: 0.9377 - val_loss: 0.2671 - val_acc: 0.9537\n",
            "Epoch 70/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2706 - acc: 0.9457 - val_loss: 0.2536 - val_acc: 0.9537\n",
            "Epoch 71/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.2576 - acc: 0.9492 - val_loss: 0.2462 - val_acc: 0.9466\n",
            "Epoch 72/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2681 - acc: 0.9403 - val_loss: 0.2598 - val_acc: 0.9466\n",
            "Epoch 73/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2552 - acc: 0.9510 - val_loss: 0.2425 - val_acc: 0.9537\n",
            "Epoch 74/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2502 - acc: 0.9466 - val_loss: 0.2350 - val_acc: 0.9680\n",
            "Epoch 75/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2469 - acc: 0.9573 - val_loss: 0.2423 - val_acc: 0.9537\n",
            "Epoch 76/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2416 - acc: 0.9519 - val_loss: 0.2662 - val_acc: 0.9288\n",
            "Epoch 77/110\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.2397 - acc: 0.9501 - val_loss: 0.1905 - val_acc: 0.9715\n",
            "Epoch 78/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2385 - acc: 0.9484 - val_loss: 0.2233 - val_acc: 0.9431\n",
            "Epoch 79/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2342 - acc: 0.9510 - val_loss: 0.2122 - val_acc: 0.9466\n",
            "Epoch 80/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.2204 - acc: 0.9555 - val_loss: 0.2232 - val_acc: 0.9573\n",
            "Epoch 81/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.2245 - acc: 0.9501 - val_loss: 0.2156 - val_acc: 0.9431\n",
            "Epoch 82/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2275 - acc: 0.9501 - val_loss: 0.2081 - val_acc: 0.9573\n",
            "Epoch 83/110\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.2220 - acc: 0.9501 - val_loss: 0.2051 - val_acc: 0.9537\n",
            "Epoch 84/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2154 - acc: 0.9492 - val_loss: 0.2197 - val_acc: 0.9609\n",
            "Epoch 85/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2103 - acc: 0.9546 - val_loss: 0.2296 - val_acc: 0.9502\n",
            "Epoch 86/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2091 - acc: 0.9564 - val_loss: 0.1898 - val_acc: 0.9715\n",
            "Epoch 87/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2036 - acc: 0.9590 - val_loss: 0.1817 - val_acc: 0.9573\n",
            "Epoch 88/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2021 - acc: 0.9573 - val_loss: 0.1726 - val_acc: 0.9786\n",
            "Epoch 89/110\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.1939 - acc: 0.9590 - val_loss: 0.1909 - val_acc: 0.9644\n",
            "Epoch 90/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1856 - acc: 0.9599 - val_loss: 0.1956 - val_acc: 0.9609\n",
            "Epoch 91/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.1886 - acc: 0.9653 - val_loss: 0.1863 - val_acc: 0.9644\n",
            "Epoch 92/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1903 - acc: 0.9564 - val_loss: 0.1768 - val_acc: 0.9609\n",
            "Epoch 93/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.1843 - acc: 0.9653 - val_loss: 0.1718 - val_acc: 0.9644\n",
            "Epoch 94/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1808 - acc: 0.9644 - val_loss: 0.1827 - val_acc: 0.9715\n",
            "Epoch 95/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.1781 - acc: 0.9608 - val_loss: 0.1552 - val_acc: 0.9751\n",
            "Epoch 96/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1766 - acc: 0.9608 - val_loss: 0.1882 - val_acc: 0.9395\n",
            "Epoch 97/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1737 - acc: 0.9644 - val_loss: 0.1536 - val_acc: 0.9680\n",
            "Epoch 98/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1683 - acc: 0.9679 - val_loss: 0.1520 - val_acc: 0.9680\n",
            "Epoch 99/110\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.1652 - acc: 0.9653 - val_loss: 0.1852 - val_acc: 0.9644\n",
            "Epoch 100/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1672 - acc: 0.9697 - val_loss: 0.1596 - val_acc: 0.9822\n",
            "Epoch 101/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1592 - acc: 0.9608 - val_loss: 0.1688 - val_acc: 0.9644\n",
            "Epoch 102/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.1536 - acc: 0.9679 - val_loss: 0.1522 - val_acc: 0.9751\n",
            "Epoch 103/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1606 - acc: 0.9653 - val_loss: 0.1593 - val_acc: 0.9573\n",
            "Epoch 104/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1551 - acc: 0.9697 - val_loss: 0.1409 - val_acc: 0.9680\n",
            "Epoch 105/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1508 - acc: 0.9662 - val_loss: 0.1566 - val_acc: 0.9680\n",
            "Epoch 106/110\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1469 - acc: 0.9697 - val_loss: 0.1466 - val_acc: 0.9786\n",
            "Epoch 107/110\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.1471 - acc: 0.9617 - val_loss: 0.1399 - val_acc: 0.9715\n",
            "Epoch 108/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1500 - acc: 0.9635 - val_loss: 0.1436 - val_acc: 0.9680\n",
            "Epoch 109/110\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1442 - acc: 0.9706 - val_loss: 0.1445 - val_acc: 0.9715\n",
            "Epoch 110/110\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1441 - acc: 0.9599 - val_loss: 0.1499 - val_acc: 0.9644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fKX_XQ_o9Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}